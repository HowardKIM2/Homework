* 디버깅 도대체 왜 하는가 ?

#include <stdio.h>

int main(void)
{
	int number = 1;
	while(1)
	{
		printf("number = %d\n", number);
		number += number;
		if(number == 100)
			break;
	}
	return 0;
}

디버깅은 컴파일은 성공적임(즉 문법 오류 없음)
하지만 논리적인 오류가 존재하는 경우에 수행하는 것임
(위와 같은 케이스에서는 2^n 으로 number 가 움직이는 것)

그 외에도 예측치 못한 다양한 문제가 존재할 수 있다.
이럴 경우에 무엇이 문제인지 파악하기 위해 디버깅을 하는 것이다.

즉 프로그램이 동작은 하는데
왜 이상한 동작을 하는지 알고자 할 때 하는 것이 디버깅이다.

gcc -g ~~~.c

gdb a.out

gdb 쉘이 뜨면 아래와 같이 입력한다.

b main
r

r 을 하는 순간 프로그램이 실행이 된다.
그리고 기존에는 si 를 활용해서 기계어를 분석했었다.
C 레벨에서 1 줄씩 진행할 수도 있는데
그럴 경우에는 s 나 n 을 입력하면 된다.

s 는 함수가 있다면 함수 내부로 진입하고 없다면 1 줄 진행
n 은 함수가 있던 없던 그냥 1 줄 진행한다.

l 은 list 의 약자로 C 코드가 보일 것이다.

c 는 다음 브레이크 포인트를 만날때까지 계속 작업함
(continue 의 약자임)



- continue 예제

#include <stdio.h>

int main(void)
{
	int number = 0;

	while(1)
	{
		number++;

		if(number == 5)
			continue;

		printf("%d\n", number);

		if(number == 10)
			break;
	}
	return 0;
}



* #define 을 사용하는 이유

예를 들어서 회사 코드에 100 번 루프(반복)
를 돌아야 하는 코드가 777 개 있다.
이때 회사 규모가 커져서 100 번 루프가 아니라
500 번 루프를 돌아야 하는 상황이 되었다고 가정!
그러면 while(i < 100) 했던 부분을
전부다 찾아서 while(i < 500) 으로 변경해야 한다.
또한 while 만 있는것이 아니라
다른 코드들도 100 이라는 숫자에 관계된 코드들이
존재할 수 있다는 것이 문제다.
그러면 숫자 하나 바꾸는것이 모든 프로그램을
뜯어고치는 대 공사가 될 수 있는데
#define TEST	100 으로 선언하고
애초에 while(i < TEST) 로 만들어놨다면
#define TEST	500 으로 1 번 변경해서
모든 변경을 대 공사 없이 수행할 수 있다.

#include <stdio.h>

int main(void)
{
  int i, result;

  for(i = 0, result = 'A'; i < 10; i++, result++)
  {
    printf("%c\n", result);
  }

  return 0;
}

* Windows 사용자일 경우 주의할점

리눅스는 for(int i = 0;~~~) 안먹힘



* goto 의 이점과 CPU 파이프라인

앞서서 만든 goto 예제는
if 와 break 를 조합한 버전과
goto 로 처리하는 버전을 가지고 있다.

if 문은 기본적으로 mov, cmp, jmp 로 구성된다.
goto 는 jmp 하나로 끝이다.

for 문이 여러개 생기면 if, break 조합의 경우
for 문의 갯수만큼 mov, cmp, jmp 를 해야 한다.
문제는 바로 jmp 명령어다.

call 이나 jmp 를 CPU Instruction(명령어) 레벨에서
분기 명령어라고 하고 이들은
CPU 파이프라인에 매우 치명적인 손실을 가져다준다.

기본적으로 아주 단순한
CPU 의 파이프라인을 설명하자면
아래와 같은 3 단계로 구성된다.

1. Fetch - 실행해야할 명령어를 물어옴
2. Decode - 어떤 명령어인지 해석함
3. Execute - 실제 명령어를 실행시킴

파이프라인이 짧은 것부터 긴 것이
5 단계 ~ 수십 단계로 구성된다.
(ARM, Intel 등등 다양한 프로세서들 모두 마찬가지)

그런데 왜 jmp 나 call 등의
분기 명령어가 문제가 될까 ?

기본적으로 분기 명령어는 파이프라인을 때려부순다.
이 뜻은 위의 가장 단순한 CPU 가
실행까지 3 clock 을 소요하는데
파이프라인이 깨지니
쓸대없이 또 다시 3 clock 을 버려야함을 의미한다.

만약 파이프라인의 단계가 수십 단계라면
분기가 여러번 발생하면
파이프라인 단계 x 분기 횟수만큼
CPU clock 을 낭비하게 된다.

즉 성능면에서도 goto 가 월등히 압도적이다.
(jmp 1 번에 끝나니까)



* SW 와 HW 동작을 생각할 때 주의할 점

SW 는 멀티 코어 상황이 아니면
어떤 상황에서도
한 번에 한 가지 동작만 실행할 수 있음

좀 더 정확하게 이야기 하자면
CPU 한 개는
오로지 한 순간에 한 가지 동작만 할 수 있음

반면 HW 회로는 병렬 회로가 존재하듯이
모든 회로가 동시에 동작할 수 있다.
파이프라인은 CPU 에 구성된 회로이기 때문에
모든 모듈들이 동시에 동작할 수 있는 것이다.
(FPGA 프로그래밍은 병렬 동작임)
실제로 CPU 설계를 FPGA 가지고함



숙제:

1. 배운 내용 복습(goto, 파이프라인, for)
2. 문제 은행(어제 내용을 for 문으로 작성함)
3. fib 함수 동작 분석(디버깅 및 그림 그리기)








































